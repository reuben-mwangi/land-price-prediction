{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Determing the Price of lands.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction\n",
        "#### Web Scrapping"
      ],
      "metadata": {
        "id": "a9qZiAQ2n5SO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LAND PRICE PREDICTION APP USING AWS SAGEMAKER'S IN-BUILT XGBOOST - End-to-End\n",
        "We will build a Land Price Prediction App to help people looking to buy land in Cameroon, get the expected price of land per quartier they intend to buy land from. The following steps will be taken:\n",
        "\n",
        "I) PROBLEM STATEMENT:\n",
        "Many people in Cameroon want to buy lands and they have trouble getting information on what to expect as price per square metre for the quartier they want to buy the land from.They also want to be able to consult the prices of several quartiers before making their final choice. This is a difficult process in Cameroon as it will mean these people who want to buy lands will have to go about making many phone calls to people asking them the price of land in those quartiers. So the objective is to scrape the data already available on the biggest Classified adds website in Cameroon (Jumia Cameroon) https://www.jumia.cm/en/land-plots\n",
        "\n",
        "This data will be cleaned and trained using the in-built XGBoost Algorithm on AWS Sagemaker, and an endpoint will be created in AWS ,which wll be used to make predictions when given the inputs like\n",
        "\n",
        "The Quartier the customer wants to buy land from\n",
        "The size of the land the customer intends to buy (in metres square)\n",
        "And the output of the model will be the predicted Price per metres square for the Quartier the customer requested.\n",
        "II) SCRAPING THE DATA:\n",
        "Scrape the data from a Classified ads website, where people post lands for sale per quartier in Cameroon.They typically type in the price per metres square and the total area of the land availlable for sale.\n",
        "\n",
        "III) PERFORM EXPLORATORY DATA ANALYSIS\n",
        "Inspect the data to validate the quality of the data scraped from the classified ads website. Analyse the distribution of missing values, outliers and gain other relevant insights from the model\n",
        "\n",
        "IV) DO FEATURE ENGINEERING & SELECTION\n",
        "Handle the mising values, outliers and do the necessary transformations which will ensure the data is well suited for the machine learning model.And also to maximise the insights gotten from the Exploratory Data Analysis phase.\n",
        "\n",
        "V) BUILD,TRAIN AND DEPLOY THE MODEL IN SAGEMAKER\n",
        "The Boto3 Container will be used to create the S3 buckets to store the preprocessed dataset.The Sagemaker's inbuilt XGBoost algorithm, will be built, trained and deployed.Including the use of optimal hyperparameters to get the best results for the RMSE( Root Mean Squared Error).An Endpoint will be created after the model is built. The Endpoint created awill be used to predict the price per metre square when the inputs of \"Quartier\" and \"Land size\" are fed to the endpoint.\n",
        "\n",
        "II) SCRAPING THE DATA\n",
        "We will perform the following tasks, in order to successully scrape the data we need\n",
        "\n",
        "a.) Importing the necessary Libraries\n",
        "b.) Writing the ETL functions to obtain the data\n",
        "c.) Scraping and storing the data to a dictionary\n",
        "d.) Saving the final scraped dataframe to a CSV file\n"
      ],
      "metadata": {
        "id": "yuAybW-yn77y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing necesary libraries"
      ],
      "metadata": {
        "id": "KMqoBkrkobX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries required to scrape the data\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "zaH9zHXZoRp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Writing ETL to extract and load data"
      ],
      "metadata": {
        "id": "qWfcdauXoyDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the  function using Request and BeautifulSoup to get the URL of the pages we will need to scrape \n",
        "def get_urls(page_number):\n",
        "    base_url = 'https://www.jumia.cm'\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.54 Safari/537.36'}\n",
        "    request = requests.get(f'https://www.jumia.cm/en/land-plots?page={page_number}&xhr=ugmii', headers)\n",
        "    soup = BeautifulSoup(request.text, 'html.parser')\n",
        "    partial_url_list = soup.find_all('article')\n",
        "    for partial_url in partial_url_list:\n",
        "        new_url = base_url + partial_url.find('a')['href']\n",
        "        url_list.append(new_url)\n",
        "        print(f\"Getting the Urls for page {page_number}\")\n",
        "    return"
      ],
      "metadata": {
        "id": "7VYSz9iHowdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function using BeautifulSoup to parse URLs from all the pages from the above function \n",
        "def extract_page(url):\n",
        "    url = url\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.54 Safari/537.36'}\n",
        "    request = requests.get(url, headers)\n",
        "    soup = BeautifulSoup(request.text, 'html.parser')\n",
        "    return soup"
      ],
      "metadata": {
        "id": "jxHDO-FTpBFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function to obtain the data we need from all those URLs above and store in a dictionary\n",
        "def transform_page(soup):\n",
        "    main_div = soup.find('div', class_='twocolumn')\n",
        "    price = main_div.find('span', {'class': 'price'}).get_text(strip=True).replace('FCFA',\"\")\n",
        "    location = main_div.select('dl > dd')[1].text.strip()\n",
        "    try:\n",
        "        area = main_div.find_all('h3')[1].get_text(strip=True).replace('Area', \"\").replace(' m2',\"\")\n",
        "    except IndexError:\n",
        "        area = ''\n",
        "\n",
        "    items = {\n",
        "        'Price': price,\n",
        "        'Location': location,\n",
        "        'Area': area\n",
        "    }\n",
        "    land_data_list.append(items)\n",
        "\n",
        "    print(f\"Scrapping the page '{soup.find('title').text}'...\")\n",
        "    return"
      ],
      "metadata": {
        "id": "9TCa6YEDpC_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Scrapping and storing data into dictionary"
      ],
      "metadata": {
        "id": "YEYqpM9UpPUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting all the URLs from page 1 to the number of pages required.In this case I just extracted 1 page as a demo\n",
        "url_list = []\n",
        "for page_number in range(1, 4):\n",
        "    get_urls(page_number)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHZiKspfpSmZ",
        "outputId": "b496cfad-8767-4842-9c66-044bdb2e5137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting the Urls for page 1\n",
            "Getting the Urls for page 1\n",
            "Getting the Urls for page 1\n",
            "Getting the Urls for page 1\n",
            "Getting the Urls for page 1\n",
            "Getting the Urls for page 1\n",
            "Getting the Urls for page 1\n",
            "Getting the Urls for page 1\n",
            "Getting the Urls for page 1\n",
            "Getting the Urls for page 2\n",
            "Getting the Urls for page 2\n",
            "Getting the Urls for page 2\n",
            "Getting the Urls for page 2\n",
            "Getting the Urls for page 2\n",
            "Getting the Urls for page 2\n",
            "Getting the Urls for page 2\n",
            "Getting the Urls for page 2\n",
            "Getting the Urls for page 2\n",
            "Getting the Urls for page 3\n",
            "Getting the Urls for page 3\n",
            "Getting the Urls for page 3\n",
            "Getting the Urls for page 3\n",
            "Getting the Urls for page 3\n",
            "Getting the Urls for page 3\n",
            "Getting the Urls for page 3\n",
            "Getting the Urls for page 3\n",
            "Getting the Urls for page 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting and Transfroming all the data from the required pages selected above\n",
        "land_data_list = []\n",
        "for url in url_list:\n",
        "    page = extract_page(url)\n",
        "    transform_page(page)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8RXp1FUpT17",
        "outputId": "4a1a3ed5-bc03-417d-daad-a99aed568bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scrapping the page 'Terrain De 250 m² Titré Loti À Vendre À Nkolafamba | Yaoundé | Jumia Deals'...\n",
            "Scrapping the page 'Terrain De 500m2 À Vendre Yassa Derrière La Station Bocom Sad | Yassa | Jumia Deals'...\n",
            "Scrapping the page 'Terrain De 1826m2 À Vendre Yassa Face Le Stade | Yassa | Jumia Deals'...\n",
            "Scrapping the page 'Terrain Titré À Vendre | PK27 | Jumia Deals'...\n",
            "Scrapping the page 'Terrain Titré À Vendre À Logpom Hôpital Catholique | Logpom | Jumia Deals'...\n",
            "Scrapping the page 'Terrain Titré À Vendre | Lendi | Jumia Deals'...\n",
            "Scrapping the page 'Terrain titré à vendre à ndogbong face collège Dauphin | Ndog-Bong | Jumia Deals'...\n",
            "Scrapping the page 'Terrain Titré À Vendre | PK19 | Jumia Deals'...\n",
            "Scrapping the page 'Terrain Titré À Vendre | Yassa | Jumia Deals'...\n",
            "Scrapping the page 'Terrain De 250 m² Titré Loti À Vendre À Nkolafamba | Yaoundé | Jumia Deals'...\n",
            "Scrapping the page 'LOT COMMERCIAL | Bonamoussadi | Jumia Deals'...\n",
            "Scrapping the page 'Terrain titré 200m² à logbessou | Logbessou | Jumia Deals'...\n",
            "Scrapping the page 'Land For Sale  | Limbé | Jumia Deals'...\n",
            "Scrapping the page 'Land For Sale  | Limbé | Jumia Deals'...\n",
            "Scrapping the page 'Land for sale  | Limbé | Jumia Deals'...\n",
            "Scrapping the page 'Land For Sale  | Buea | Jumia Deals'...\n",
            "Scrapping the page 'Land For Sale  | Limbé | Jumia Deals'...\n",
            "Scrapping the page 'Land for Sale  | Limbé | Jumia Deals'...\n",
            "Scrapping the page 'Terrain De 250 m² Titré Loti À Vendre À Nkolafamba | Yaoundé | Jumia Deals'...\n",
            "Scrapping the page 'Terrain Titré | Lendi | Jumia Deals'...\n",
            "Scrapping the page 'Land for Sale  | Limbé | Jumia Deals'...\n",
            "Scrapping the page 'Land for Sale  | Limbé | Jumia Deals'...\n",
            "Scrapping the page 'Terrain Titré À Vendre | PK21 | Jumia Deals'...\n",
            "Scrapping the page 'Terrain Titré À Vendre | Bonaberi | Jumia Deals'...\n",
            "Scrapping the page 'Land for Sale  | Limbé | Jumia Deals'...\n",
            "Scrapping the page 'Land for sale  | Limbé | Jumia Deals'...\n",
            "Scrapping the page 'Land For Sale  | Limbé | Jumia Deals'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the scrapped data as csv"
      ],
      "metadata": {
        "id": "d2t2PUljpg1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a pandas dataframe\n",
        "df = pd.DataFrame(land_data_list)\n",
        "print('Printing first 05 elements...')\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utczbW9SpZ4a",
        "outputId": "e76de302-1ce7-4316-a2e1-99a6ad6da08a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing first 05 elements...\n",
            "        Price Location  Area\n",
            "0       2,150  Yaoundé   250\n",
            "1      25,000    Yassa   500\n",
            "2      70,000    Yassa  1826\n",
            "3       6,000     PK27   250\n",
            "4  12,000,000   Logpom   200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PwIRGzCptEx",
        "outputId": "366be33e-afb6-41ba-d0ab-bf63db23c056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27 entries, 0 to 26\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Price     27 non-null     object\n",
            " 1   Location  27 non-null     object\n",
            " 2   Area      27 non-null     object\n",
            "dtypes: object(3)\n",
            "memory usage: 776.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Formating Area and Price Columns from text to numeric\n",
        "df['Area'].replace({' m2':'',',': ''},regex = True,inplace = True)\n",
        "df['Area'] = pd.to_numeric(df['Area'],errors = 'coerce')\n",
        "\n",
        "df['Price'].replace({'FCFA':'',',': ''},regex = True,inplace = True)\n",
        "df['Price'] = pd.to_numeric(df['Price'])"
      ],
      "metadata": {
        "id": "Itoh2Nj-pukE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UgdHB9Dp5aJ",
        "outputId": "2d80457c-aa87-4508-ad40-bc70f995aa84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27 entries, 0 to 26\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Price     27 non-null     int64 \n",
            " 1   Location  27 non-null     object\n",
            " 2   Area      27 non-null     int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 776.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('land_price_data.csv',index = False)\n",
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "iYaFvKaIp6lq",
        "outputId": "21e06ba5-0add-4e9d-9e9c-f8721e1ce779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Price   Location  Area\n",
              "0      2150    Yaoundé   250\n",
              "1     25000      Yassa   500\n",
              "2     70000      Yassa  1826\n",
              "3      6000       PK27   250\n",
              "4  12000000     Logpom   200\n",
              "5      9000      Lendi   500\n",
              "6     60000  Ndog-Bong   512\n",
              "7     17000       PK19   500\n",
              "8      7000      Yassa  3000\n",
              "9      2150    Yaoundé   250"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07ae27e8-f1dd-467a-ad37-9dd71efd3158\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>Location</th>\n",
              "      <th>Area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2150</td>\n",
              "      <td>Yaoundé</td>\n",
              "      <td>250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25000</td>\n",
              "      <td>Yassa</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70000</td>\n",
              "      <td>Yassa</td>\n",
              "      <td>1826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6000</td>\n",
              "      <td>PK27</td>\n",
              "      <td>250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12000000</td>\n",
              "      <td>Logpom</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>9000</td>\n",
              "      <td>Lendi</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>60000</td>\n",
              "      <td>Ndog-Bong</td>\n",
              "      <td>512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>17000</td>\n",
              "      <td>PK19</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7000</td>\n",
              "      <td>Yassa</td>\n",
              "      <td>3000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2150</td>\n",
              "      <td>Yaoundé</td>\n",
              "      <td>250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07ae27e8-f1dd-467a-ad37-9dd71efd3158')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07ae27e8-f1dd-467a-ad37-9dd71efd3158 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07ae27e8-f1dd-467a-ad37-9dd71efd3158');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Great!!! We have finally scraped the data from the clasified adds website and saved as a csv (land_price_data.csv).Let us move on the the next phase of Exploratory Data Analysis."
      ],
      "metadata": {
        "id": "0BU_6GGGqKsD"
      }
    }
  ]
}